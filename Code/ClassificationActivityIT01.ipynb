{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for ml classificaiton\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test datasets\n",
    "train = pd.read_csv('../CSV/train_set_it01.csv')\n",
    "test = pd.read_csv('../CSV/test_set_it01.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GjaeRecId                        0\n",
      "LedgerDimension                  0\n",
      "GroupChartOfAccountsValue        0\n",
      "Ledger                           0\n",
      "PostingLayer                     0\n",
      "SubledgerVoucher                 0\n",
      "CreatedBy                        0\n",
      "MainAccount                      0\n",
      "Text                             0\n",
      "JournalType                  10906\n",
      "JournalTypeLabel             10906\n",
      "NumOfLines                   10906\n",
      "CountLedgerJournal           10906\n",
      "TransactionCurrencyAmount        0\n",
      "TransactionCurrencyCode          0\n",
      "Activity                         0\n",
      "dtype: int64\n",
      "GjaeRecId                        0\n",
      "LedgerDimension                  0\n",
      "GroupChartOfAccountsValue        0\n",
      "Ledger                           0\n",
      "PostingLayer                     0\n",
      "SubledgerVoucher                 0\n",
      "CreatedBy                        0\n",
      "MainAccount                      0\n",
      "Text                            27\n",
      "JournalType                  38799\n",
      "JournalTypeLabel             38799\n",
      "NumOfLines                   38799\n",
      "CountLedgerJournal           38799\n",
      "TransactionCurrencyAmount        0\n",
      "TransactionCurrencyCode          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(train.isnull().sum())\n",
    "print(test.isnull().sum())\n",
    "\n",
    "# Drop columns with missing values (JournalType, JournalTypeLabel, NumOfLines, CountLedgerJournal)\n",
    "train = train.drop(['JournalType', 'JournalTypeLabel', 'NumOfLines', 'CountLedgerJournal'], axis=1)\n",
    "test = test.drop(['JournalType', 'JournalTypeLabel', 'NumOfLines', 'CountLedgerJournal'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where column Text is null in test set\n",
    "test = test.dropna(subset=['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64000, 12)\n",
      "(38944, 11)\n"
     ]
    }
   ],
   "source": [
    "# Show the number of observations and features\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GjaeRecId                    63959\n",
      "LedgerDimension               5605\n",
      "GroupChartOfAccountsValue      162\n",
      "Ledger                           1\n",
      "PostingLayer                     3\n",
      "SubledgerVoucher             40362\n",
      "CreatedBy                       25\n",
      "MainAccount                    366\n",
      "Text                         37375\n",
      "TransactionCurrencyAmount    34556\n",
      "TransactionCurrencyCode          1\n",
      "Activity                         8\n",
      "dtype: int64\n",
      "GjaeRecId                    38944\n",
      "LedgerDimension               4610\n",
      "GroupChartOfAccountsValue      135\n",
      "Ledger                           1\n",
      "PostingLayer                     3\n",
      "SubledgerVoucher              5418\n",
      "CreatedBy                        8\n",
      "MainAccount                    292\n",
      "Text                          5373\n",
      "TransactionCurrencyAmount    20526\n",
      "TransactionCurrencyCode          1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check unique values for each column\n",
    "print(train.nunique())\n",
    "print(test.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity\n",
      "ACT01    8000\n",
      "ACT03    8000\n",
      "ACT07    8000\n",
      "ACT09    8000\n",
      "ACT13    8000\n",
      "ACT15    8000\n",
      "ACT17    8000\n",
      "ACT32    8000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print values of Activity columm\n",
    "print(train['Activity'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop column Ledger and TransactionCurrencyCode\n",
    "train = train.drop(['GjaeRecId', 'Ledger', 'SubledgerVoucher', 'TransactionCurrencyCode', 'TransactionCurrencyAmount'], axis=1)\n",
    "test = test.drop(['Ledger', 'SubledgerVoucher', 'TransactionCurrencyCode', 'TransactionCurrencyAmount'], axis=1)\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64000, 7)\n",
      "(38944, 7)\n",
      "   LedgerDimension GroupChartOfAccountsValue  PostingLayer   \n",
      "0       5637173888                    A10420             0  \\\n",
      "1       5645293726                  E41040IC             0   \n",
      "2       5637830841                  E41040IC             0   \n",
      "3       5637175101                    L20200             0   \n",
      "4       5644324475                    L20200             0   \n",
      "\n",
      "              CreatedBy  MainAccount   \n",
      "0  giovanna.santostefan   5637145546  \\\n",
      "1     annamaria.massara   5637145765   \n",
      "2  giovanna.santostefan   5637145765   \n",
      "3  giovanna.santostefan   5637145525   \n",
      "4  giovanna.santostefan   5637145525   \n",
      "\n",
      "                                                Text Activity  \n",
      "0               TERRATURISMO - ospitalità AMEX 02/18    ACT01  \n",
      "1  LEASEPLAN - CANONI SERVIZI AUTO GALLO  GF247CD...    ACT01  \n",
      "2  LEASEPLAN - Canoni Leasing Auto VILLA EX822AD ...    ACT01  \n",
      "3                        MANPOWER - interinali 05/18    ACT01  \n",
      "4                            OSCAR - TAXI 05-06/2022    ACT01  \n"
     ]
    }
   ],
   "source": [
    "# Show the number of observations and features\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LedgerDimension  GroupChartOfAccountsValue  PostingLayer  CreatedBy   \n",
      "0       5637173888                          8             0         12  \\\n",
      "1       5645293726                         58             0          4   \n",
      "2       5637830841                         58             0         12   \n",
      "3       5637175101                        125             0         12   \n",
      "4       5644324475                        125             0         12   \n",
      "\n",
      "   MainAccount                                               Text  Activity  \n",
      "0           85               TERRATURISMO - ospitalità AMEX 02/18         0  \n",
      "1          250  LEASEPLAN - CANONI SERVIZI AUTO GALLO  GF247CD...         0  \n",
      "2          250  LEASEPLAN - Canoni Leasing Auto VILLA EX822AD ...         0  \n",
      "3           72                        MANPOWER - interinali 05/18         0  \n",
      "4           72                            OSCAR - TAXI 05-06/2022         0  \n"
     ]
    }
   ],
   "source": [
    "# Encode GroupChartOfAccountsValue column to numeric values \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "train['GroupChartOfAccountsValue'] = le.fit_transform(train['GroupChartOfAccountsValue'])\n",
    "test['GroupChartOfAccountsValue'] = le.fit_transform(test['GroupChartOfAccountsValue'])\n",
    "\n",
    "# Encode Activity column to numeric values\n",
    "le = LabelEncoder()\n",
    "train['Activity'] = le.fit_transform(train['Activity'])\n",
    "\n",
    "# Encode CreatedBy column to numeric values \n",
    "le = LabelEncoder()\n",
    "train['CreatedBy'] = le.fit_transform(train['CreatedBy'])\n",
    "test['CreatedBy'] = le.fit_transform(test['CreatedBy'])\n",
    "\n",
    "# Encode MainAccount column to numeric values\n",
    "le = LabelEncoder()\n",
    "train['MainAccount'] = le.fit_transform(train['MainAccount'])\n",
    "test['MainAccount'] = le.fit_transform(test['MainAccount'])\n",
    "\n",
    "\n",
    "print(train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LedgerDimension  GroupChartOfAccountsValue  PostingLayer  CreatedBy   \n",
      "0       5637173888                          8             0          4  \\\n",
      "1       5637191649                         91             0          4   \n",
      "2       5644326715                         25             0          4   \n",
      "3       5637176287                          2             0         16   \n",
      "4       5637176289                          1             0         16   \n",
      "\n",
      "   MainAccount                                               Text  Activity  \n",
      "0           85  ENI - carb. auto aziend-EV213NN - 05/18 LOGISTICA         0  \n",
      "1          247                         BNP - A1A42102 spese 05/18         0  \n",
      "2            4                        109000239, Spit fixed asset         5  \n",
      "3           30             Settlement: 2000063-2020, 2000063-2020         3  \n",
      "4           55                     SINDACATI - pag. quote 03.2019         4  \n",
      "    GjaeRecId  LedgerDimension  GroupChartOfAccountsValue  PostingLayer   \n",
      "0  5741823175       5647352062                         32             0  \\\n",
      "1  5669250005       5642216682                         32             0   \n",
      "2  5669249923       5643674652                         32             0   \n",
      "3  5653582436       5637176082                         33             0   \n",
      "4  5746894466       5650591330                         32             0   \n",
      "\n",
      "   CreatedBy  MainAccount                                               Text  \n",
      "0          2          216  Trans REV: , 4000048967 FERIE GODUTE E ORE NON...  \n",
      "1          2          216  Trans REV: , 4000033606FERIE GODUTE E ORE NON ...  \n",
      "2          2          216  Trans REV: , 4000033606FERIE GODUTE E ORE NON ...  \n",
      "3          2          217                            Trans REV: , 4000027463  \n",
      "4          2          216  Trans REV: , 4000049873 FERIE GODUTE E ORE NON...  \n"
     ]
    }
   ],
   "source": [
    "# mescolare i dati\n",
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(train.head())\n",
    "print(test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove numbers from the rows in the 'Text' column of the train dataset\n",
    "train['Text'] = train['Text'].str.replace('\\d+', '')\n",
    "\n",
    "# Remove numbers from the rows in the 'Text' column of the test dataset\n",
    "test['Text'] = test['Text'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation and convert text to lowercase in the 'Text' column of 'train'\n",
    "train['Text'] = train['Text'].str.replace('[^\\w\\s]','').str.lower()\n",
    "\n",
    "# Remove punctuation and convert text to lowercase in the 'Text' column of 'test'\n",
    "test['Text'] = test['Text'].str.replace('[^\\w\\s]','').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TF-IDF vectorizer to convert the text of the law into a matrix of TF-IDF features\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "# Fit and transform the TF-IDF vectorizer on the 'Text' column in 'train'\n",
    "tfidf_train = vectorizer.fit_transform(train['Text'])\n",
    "\n",
    "# Transform the 'Text' column in 'test'\n",
    "tfidf_test = vectorizer.transform(test['Text'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80640625\n",
      "[[1555   40]\n",
      " [ 144 1143]]\n"
     ]
    }
   ],
   "source": [
    "# Split the train dataset into train and validation sets \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(tfidf_train, train['Activity'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Import the Multinomial Naive Bayes classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Instantiate the MultinomialNB classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(X_val)\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_val, pred)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_val, pred, labels=[0, 1])\n",
    "print(cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\colig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\colig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\colig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\colig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\colig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\colig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "30 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\colig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\colig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\colig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\colig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\colig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan 0.68689453        nan 0.73529297        nan 0.78160156\n",
      "        nan 0.82066406        nan 0.82484375        nan 0.8225    ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameter: {'C': 10, 'penalty': 'l2'}\n",
      "Tuned Logistic Regression Accuracy: 0.82484375\n"
     ]
    }
   ],
   "source": [
    "# Model selection for the logistic regression classifier using GridSearchCV \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "# c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2']}\n",
    "logreg = LogisticRegression(random_state=42, max_iter=700, verbose=2)\n",
    "\n",
    "# Instantiate the GridSearchCV object\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n",
    "\n",
    "# Fit it to the training data\n",
    "logreg_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the optimal parameters and best score\n",
    "print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n",
    "print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.825625\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95      1617\n",
      "           1       0.67      0.74      0.70      1613\n",
      "           2       0.99      1.00      0.99      1633\n",
      "           3       0.75      0.72      0.73      1552\n",
      "           4       0.79      0.79      0.79      1602\n",
      "           5       0.84      0.70      0.77      1598\n",
      "           6       0.75      0.86      0.80      1593\n",
      "           7       0.90      0.84      0.87      1592\n",
      "\n",
      "    accuracy                           0.83     12800\n",
      "   macro avg       0.83      0.82      0.82     12800\n",
      "weighted avg       0.83      0.83      0.83     12800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict the labels of the test set: y_pred using the logistic regression classifier with the best parameters \n",
    "y_pred = logreg_cv.predict(X_val)\n",
    "\n",
    "# Compute and print metrics\n",
    "print(\"Accuracy: {}\".format(logreg_cv.score(X_val, y_val)))\n",
    "print(\"Classification Report:\\n {}\".format(metrics.classification_report(y_val, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the model a Neural Network (MLPClassifier)\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# mlp = MLPClassifier(hidden_layer_sizes=(100, 50), random_state=42, verbose=True)\n",
    "# mlp.fit(X_train, y_train)\n",
    "\n",
    "# # Predict the labels of the test set: y_pred\n",
    "# y_pred = mlp.predict(X_val)\n",
    "\n",
    "# # Calculate the accuracy score: score\n",
    "# score = metrics.accuracy_score(y_val, y_pred)\n",
    "# print(score)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

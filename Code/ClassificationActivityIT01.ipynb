{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for ml classificaiton\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test datasets\n",
    "train = pd.read_csv('../CSV/train_set_it01.csv')\n",
    "test = pd.read_csv('../CSV/test_set_it01.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GjaeRecId                        0\n",
      "LedgerDimension                  0\n",
      "GroupChartOfAccountsValue        0\n",
      "Ledger                           0\n",
      "PostingLayer                     0\n",
      "SubledgerVoucher                 0\n",
      "CreatedBy                        0\n",
      "MainAccount                      0\n",
      "Text                             0\n",
      "JournalType                  10906\n",
      "JournalTypeLabel             10906\n",
      "NumOfLines                   10906\n",
      "CountLedgerJournal           10906\n",
      "TransactionCurrencyAmount        0\n",
      "TransactionCurrencyCode          0\n",
      "Activity                         0\n",
      "dtype: int64\n",
      "GjaeRecId                        0\n",
      "LedgerDimension                  0\n",
      "GroupChartOfAccountsValue        0\n",
      "Ledger                           0\n",
      "PostingLayer                     0\n",
      "SubledgerVoucher                 0\n",
      "CreatedBy                        0\n",
      "MainAccount                      0\n",
      "Text                            27\n",
      "JournalType                  38799\n",
      "JournalTypeLabel             38799\n",
      "NumOfLines                   38799\n",
      "CountLedgerJournal           38799\n",
      "TransactionCurrencyAmount        0\n",
      "TransactionCurrencyCode          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(train.isnull().sum())\n",
    "print(test.isnull().sum())\n",
    "\n",
    "# Drop columns with missing values (JournalType, JournalTypeLabel, NumOfLines, CountLedgerJournal)\n",
    "train = train.drop(['JournalType', 'JournalTypeLabel', 'NumOfLines', 'CountLedgerJournal'], axis=1)\n",
    "test = test.drop(['JournalType', 'JournalTypeLabel', 'NumOfLines', 'CountLedgerJournal'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where column Text is null in test set\n",
    "test = test.dropna(subset=['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64000, 12)\n",
      "(38944, 11)\n"
     ]
    }
   ],
   "source": [
    "# Show the number of observations and features\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GjaeRecId                    63959\n",
      "LedgerDimension               5605\n",
      "GroupChartOfAccountsValue      162\n",
      "Ledger                           1\n",
      "PostingLayer                     3\n",
      "SubledgerVoucher             40362\n",
      "CreatedBy                       25\n",
      "MainAccount                    366\n",
      "Text                         37375\n",
      "TransactionCurrencyAmount    34556\n",
      "TransactionCurrencyCode          1\n",
      "Activity                         8\n",
      "dtype: int64\n",
      "GjaeRecId                    38944\n",
      "LedgerDimension               4610\n",
      "GroupChartOfAccountsValue      135\n",
      "Ledger                           1\n",
      "PostingLayer                     3\n",
      "SubledgerVoucher              5418\n",
      "CreatedBy                        8\n",
      "MainAccount                    292\n",
      "Text                          5373\n",
      "TransactionCurrencyAmount    20526\n",
      "TransactionCurrencyCode          1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check unique values for each column\n",
    "print(train.nunique())\n",
    "print(test.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity\n",
      "ACT01    8000\n",
      "ACT03    8000\n",
      "ACT07    8000\n",
      "ACT09    8000\n",
      "ACT13    8000\n",
      "ACT15    8000\n",
      "ACT17    8000\n",
      "ACT32    8000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print values of Activity columm\n",
    "print(train['Activity'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop column Ledger and TransactionCurrencyCode\n",
    "train = train.drop(['GjaeRecId', 'Ledger', 'SubledgerVoucher', 'TransactionCurrencyCode', 'TransactionCurrencyAmount'], axis=1)\n",
    "test = test.drop(['Ledger', 'SubledgerVoucher', 'TransactionCurrencyCode', 'TransactionCurrencyAmount'], axis=1)\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64000, 7)\n",
      "(38944, 7)\n",
      "   LedgerDimension GroupChartOfAccountsValue  PostingLayer   \n",
      "0       5637173888                    A10420             0  \\\n",
      "1       5645293726                  E41040IC             0   \n",
      "2       5637830841                  E41040IC             0   \n",
      "3       5637175101                    L20200             0   \n",
      "4       5644324475                    L20200             0   \n",
      "\n",
      "              CreatedBy  MainAccount   \n",
      "0  giovanna.santostefan   5637145546  \\\n",
      "1     annamaria.massara   5637145765   \n",
      "2  giovanna.santostefan   5637145765   \n",
      "3  giovanna.santostefan   5637145525   \n",
      "4  giovanna.santostefan   5637145525   \n",
      "\n",
      "                                                Text Activity  \n",
      "0               TERRATURISMO - ospitalità AMEX 02/18    ACT01  \n",
      "1  LEASEPLAN - CANONI SERVIZI AUTO GALLO  GF247CD...    ACT01  \n",
      "2  LEASEPLAN - Canoni Leasing Auto VILLA EX822AD ...    ACT01  \n",
      "3                        MANPOWER - interinali 05/18    ACT01  \n",
      "4                            OSCAR - TAXI 05-06/2022    ACT01  \n"
     ]
    }
   ],
   "source": [
    "# Show the number of observations and features\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LedgerDimension  GroupChartOfAccountsValue  PostingLayer  CreatedBy   \n",
      "0       5637173888                          8             0         12  \\\n",
      "1       5645293726                         58             0          4   \n",
      "2       5637830841                         58             0         12   \n",
      "3       5637175101                        125             0         12   \n",
      "4       5644324475                        125             0         12   \n",
      "\n",
      "   MainAccount                                               Text  Activity  \n",
      "0           85               TERRATURISMO - ospitalità AMEX 02/18         0  \n",
      "1          250  LEASEPLAN - CANONI SERVIZI AUTO GALLO  GF247CD...         0  \n",
      "2          250  LEASEPLAN - Canoni Leasing Auto VILLA EX822AD ...         0  \n",
      "3           72                        MANPOWER - interinali 05/18         0  \n",
      "4           72                            OSCAR - TAXI 05-06/2022         0  \n"
     ]
    }
   ],
   "source": [
    "# Encode GroupChartOfAccountsValue column to numeric values \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "train['GroupChartOfAccountsValue'] = le.fit_transform(train['GroupChartOfAccountsValue'])\n",
    "test['GroupChartOfAccountsValue'] = le.fit_transform(test['GroupChartOfAccountsValue'])\n",
    "\n",
    "# Encode Activity column to numeric values\n",
    "le = LabelEncoder()\n",
    "train['Activity'] = le.fit_transform(train['Activity'])\n",
    "\n",
    "# Encode CreatedBy column to numeric values \n",
    "le = LabelEncoder()\n",
    "train['CreatedBy'] = le.fit_transform(train['CreatedBy'])\n",
    "test['CreatedBy'] = le.fit_transform(test['CreatedBy'])\n",
    "\n",
    "# Encode MainAccount column to numeric values\n",
    "le = LabelEncoder()\n",
    "train['MainAccount'] = le.fit_transform(train['MainAccount'])\n",
    "test['MainAccount'] = le.fit_transform(test['MainAccount'])\n",
    "\n",
    "\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LedgerDimension  GroupChartOfAccountsValue  PostingLayer  CreatedBy   \n",
      "0       5641565505                         26             0         12  \\\n",
      "1       5637179139                        149             0         16   \n",
      "2       5637176336                          1             0         16   \n",
      "3       5637175105                        142             0         17   \n",
      "4       5638032040                          2             0         16   \n",
      "\n",
      "   MainAccount                                               Text  Activity  \n",
      "0            8                             Z32, Ammortamento Mese         6  \n",
      "1          145  SO/Ledger - invoice: SO0002404, Manpower Talen...         2  \n",
      "2           50  SINDACATI - pag. quote 04.2018 e comm. bancari...         4  \n",
      "3           77                    TELECOM 0686399009 canone 09/17         7  \n",
      "4           38                       TLS GROUP -inc . Ft. 7/50-51         3  \n",
      "    GjaeRecId  LedgerDimension  GroupChartOfAccountsValue  PostingLayer   \n",
      "0  5741823175       5647352062                         32             0  \\\n",
      "1  5669250005       5642216682                         32             0   \n",
      "2  5669249923       5643674652                         32             0   \n",
      "3  5653582436       5637176082                         33             0   \n",
      "4  5746894466       5650591330                         32             0   \n",
      "\n",
      "   CreatedBy  MainAccount                                               Text  \n",
      "0          2          216  Trans REV: , 4000048967 FERIE GODUTE E ORE NON...  \n",
      "1          2          216  Trans REV: , 4000033606FERIE GODUTE E ORE NON ...  \n",
      "2          2          216  Trans REV: , 4000033606FERIE GODUTE E ORE NON ...  \n",
      "3          2          217                            Trans REV: , 4000027463  \n",
      "4          2          216  Trans REV: , 4000049873 FERIE GODUTE E ORE NON...  \n"
     ]
    }
   ],
   "source": [
    "# mescolare i dati\n",
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(train.head())\n",
    "print(test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove numbers from the rows in the 'Text' column of the train dataset\n",
    "train['Text'] = train['Text'].str.replace('\\d+', '')\n",
    "\n",
    "# Remove numbers from the rows in the 'Text' column of the test dataset\n",
    "test['Text'] = test['Text'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation and convert text to lowercase in the 'Text' column of 'train'\n",
    "train['Text'] = train['Text'].str.replace('[^\\w\\s]','').str.lower()\n",
    "\n",
    "# Remove punctuation and convert text to lowercase in the 'Text' column of 'test'\n",
    "test['Text'] = test['Text'].str.replace('[^\\w\\s]','').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TF-IDF vectorizer to convert the text of the law into a matrix of TF-IDF features\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "# Fit and transform the TF-IDF vectorizer on the 'Text' column in 'train'\n",
    "tfidf_train = vectorizer.fit_transform(train['Text'])\n",
    "\n",
    "# Remove GjaeRecId column from test set and save it in a variable\n",
    "GjaeRecId = test['GjaeRecId']\n",
    "test = test.drop(['GjaeRecId'], axis=1)\n",
    "\n",
    "# Transform the 'Text' column in 'test'\n",
    "tfidf_test = vectorizer.transform(test['Text'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.812265625\n",
      "[[1608   45]\n",
      " [ 136 1145]]\n"
     ]
    }
   ],
   "source": [
    "# Split the train dataset into train and validation sets \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(tfidf_train, train['Activity'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Import the Multinomial Naive Bayes classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Instantiate the MultinomialNB classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(X_val)\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_val, pred)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_val, pred, labels=[0, 1])\n",
    "print(cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\colig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\colig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\colig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\colig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\colig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\colig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "30 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\colig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\colig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\colig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\colig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\colig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan 0.70470703        nan 0.73337891        nan 0.77976563\n",
      "        nan 0.8184375         nan 0.824375          nan 0.82173828]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameter: {'C': 10, 'penalty': 'l2'}\n",
      "Tuned Logistic Regression Accuracy: 0.8243750000000001\n"
     ]
    }
   ],
   "source": [
    "# Model selection for the logistic regression classifier using GridSearchCV \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "# c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2']}\n",
    "logreg = LogisticRegression(random_state=42, max_iter=700, verbose=2)\n",
    "\n",
    "# Instantiate the GridSearchCV object\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n",
    "\n",
    "# Fit it to the training data\n",
    "logreg_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the optimal parameters and best score\n",
    "print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n",
    "print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.831015625\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1675\n",
      "           1       0.65      0.77      0.71      1565\n",
      "           2       0.99      0.99      0.99      1567\n",
      "           3       0.77      0.72      0.75      1615\n",
      "           4       0.81      0.80      0.80      1644\n",
      "           5       0.86      0.69      0.76      1538\n",
      "           6       0.75      0.88      0.81      1563\n",
      "           7       0.91      0.83      0.87      1633\n",
      "\n",
      "    accuracy                           0.83     12800\n",
      "   macro avg       0.84      0.83      0.83     12800\n",
      "weighted avg       0.84      0.83      0.83     12800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict the labels of the test set: y_pred using the logistic regression classifier with the best parameters \n",
    "y_pred = logreg_cv.predict(X_val)\n",
    "\n",
    "# Compute and print metrics\n",
    "print(\"Accuracy: {}\".format(logreg_cv.score(X_val, y_val)))\n",
    "print(\"Classification Report:\\n {}\".format(metrics.classification_report(y_val, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38944, 89147)\n"
     ]
    }
   ],
   "source": [
    "# shape test\n",
    "print(tfidf_test.shape)\n",
    "\n",
    "# Predict the labels of the test set: y_pred using the logistic regression classifier with the best parameters\n",
    "Activity_prediction = logreg_cv.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column GjaeRecId to the test set as first column and Activity_prediction as last column\n",
    "test.insert(0, 'GjaeRecId', GjaeRecId)\n",
    "test.insert(6, 'Activity', Activity_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    GjaeRecId  LedgerDimension  GroupChartOfAccountsValue  PostingLayer   \n",
      "0  5741823175       5647352062                         32             0  \\\n",
      "1  5669250005       5642216682                         32             0   \n",
      "2  5669249923       5643674652                         32             0   \n",
      "3  5653582436       5637176082                         33             0   \n",
      "4  5746894466       5650591330                         32             0   \n",
      "\n",
      "   CreatedBy  MainAccount  Activity   \n",
      "0          2          216         7  \\\n",
      "1          2          216         7   \n",
      "2          2          216         7   \n",
      "3          2          217         7   \n",
      "4          2          216         7   \n",
      "\n",
      "                                                Text  \n",
      "0  trans rev: , 4000048967 ferie godute e ore non...  \n",
      "1  trans rev: , 4000033606ferie godute e ore non ...  \n",
      "2  trans rev: , 4000033606ferie godute e ore non ...  \n",
      "3                            trans rev: , 4000027463  \n",
      "4  trans rev: , 4000049873 ferie godute e ore non...  \n"
     ]
    }
   ],
   "source": [
    "# Head of test set\n",
    "print(test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity\n",
      "7    38396\n",
      "0      378\n",
      "5       76\n",
      "1       55\n",
      "4       33\n",
      "3        2\n",
      "6        2\n",
      "2        2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print number of unique values for column activity in test set\n",
    "print(test['Activity'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the model a Neural Network (MLPClassifier)\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# mlp = MLPClassifier(hidden_layer_sizes=(100, 50), random_state=42, verbose=True)\n",
    "# mlp.fit(X_train, y_train)\n",
    "\n",
    "# # Predict the labels of the test set: y_pred\n",
    "# y_pred = mlp.predict(X_val)\n",
    "\n",
    "# # Calculate the accuracy score: score\n",
    "# score = metrics.accuracy_score(y_val, y_pred)\n",
    "# print(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38944, 15)\n",
      "    GjaeRecId  LedgerDimension GroupChartOfAccountsValue      Ledger   \n",
      "0  5741823175       5647352062                    E41035  5637145326  \\\n",
      "1  5669250005       5642216682                    E41035  5637145326   \n",
      "2  5669249923       5643674652                    E41035  5637145326   \n",
      "3  5653582436       5637176082                  E41035IC  5637145326   \n",
      "4  5746894466       5650591330                    E41035  5637145326   \n",
      "\n",
      "   PostingLayer SubledgerVoucher             CreatedBy  MainAccount   \n",
      "0             0        LTR009125  giovanna.santostefan   5637145783  \\\n",
      "1             0        LTR006875  giovanna.santostefan   5637145783   \n",
      "2             0        LTR006875  giovanna.santostefan   5637145783   \n",
      "3             0          LTR5913  giovanna.santostefan   5637145784   \n",
      "4             0        LTR009303  giovanna.santostefan   5637145783   \n",
      "\n",
      "                                                Text  JournalType   \n",
      "0  Trans REV: , 4000048967 FERIE GODUTE E ORE NON...          NaN  \\\n",
      "1  Trans REV: , 4000033606FERIE GODUTE E ORE NON ...          NaN   \n",
      "2  Trans REV: , 4000033606FERIE GODUTE E ORE NON ...          NaN   \n",
      "3                            Trans REV: , 4000027463          NaN   \n",
      "4  Trans REV: , 4000049873 FERIE GODUTE E ORE NON...          NaN   \n",
      "\n",
      "  JournalTypeLabel  NumOfLines  CountLedgerJournal TransactionCurrencyAmount   \n",
      "0              NaN         NaN                 NaN                   -650000  \\\n",
      "1              NaN         NaN                 NaN                 -13560000   \n",
      "2              NaN         NaN                 NaN                   2470000   \n",
      "3              NaN         NaN                 NaN                   2100000   \n",
      "4              NaN         NaN                 NaN                   -250000   \n",
      "\n",
      "  TransactionCurrencyCode  Activity  \n",
      "0                     EUR         7  \n",
      "1                     EUR         7  \n",
      "2                     EUR         7  \n",
      "3                     EUR         7  \n",
      "4                     EUR         7  \n"
     ]
    }
   ],
   "source": [
    "it_01 = pd.read_csv('../CSV/test_set_it01.csv', sep=';')\n",
    "\n",
    "# remove rows with null values in column Text\n",
    "it_01 = it_01.dropna(subset=['Text'])\n",
    "\n",
    "# Shape of it_01\n",
    "print(it_01.shape)\n",
    "\n",
    "# Add column Activity to it_01 as last column\n",
    "it_01.insert(15, 'Activity', Activity_prediction)\n",
    "\n",
    "# Head of it_01\n",
    "print(it_01.head())\n",
    "\n",
    "# Save it_01 as csv file \n",
    "it_01.to_csv('it_01.csv', index=False, sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

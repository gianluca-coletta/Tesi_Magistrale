{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6074943, 7)\n",
      "(2444386, 6)\n"
     ]
    }
   ],
   "source": [
    "# Load train and test datasets\n",
    "train = pd.read_csv('../CSV/train_set.csv', sep=';')\n",
    "print(train.shape)\n",
    "\n",
    "test = pd.read_csv('../CSV/test_set.csv', sep=';')\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['GjaeRecId', 'GroupChartOfAccountsValue', 'PostingLayer',\n",
      "       'SubledgerVoucherDataAreaId', 'CreatedBy', 'Text', 'Id'],\n",
      "      dtype='object')\n",
      "Index(['5637145810', 'A11115B', '0', 'RO01', 'Admin',\n",
      "       'FXA MIGRATION 31/07/17'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print name of columns in datasets \n",
    "print(train.columns)\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['GjaeRecId', 'GroupChartOfAccountsValue', 'PostingLayer',\n",
      "       'SubledgerVoucherDataAreaId', 'CreatedBy', 'Text'],\n",
      "      dtype='object')\n",
      "(2444386, 6)\n",
      "Index(['GjaeRecId', 'GroupChartOfAccountsValue', 'PostingLayer',\n",
      "       'SubledgerVoucherDataAreaId', 'CreatedBy', 'Text', 'Activity'],\n",
      "      dtype='object')\n",
      "(6074943, 7)\n"
     ]
    }
   ],
   "source": [
    "# Give this name columns to test set: 'GjaeRecId', 'GroupChartOfAccountsValue', 'PostingLayer', 'SubledgerVoucherDataAreaId', 'CreatedBy', 'Text'\n",
    "test.columns = ['GjaeRecId', 'GroupChartOfAccountsValue', 'PostingLayer', 'SubledgerVoucherDataAreaId', 'CreatedBy', 'Text']\n",
    "train.columns = ['GjaeRecId', 'GroupChartOfAccountsValue', 'PostingLayer', 'SubledgerVoucherDataAreaId', 'CreatedBy', 'Text', 'Activity']\n",
    "\n",
    "# Print name of columns in datasets\n",
    "print(test.columns)\n",
    "print(test.shape)\n",
    "print(train.columns)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity\n",
      "ACT17    600000\n",
      "ACT44    600000\n",
      "ACT32    600000\n",
      "ACT09    600000\n",
      "ACT15    600000\n",
      "ACT07    600000\n",
      "ACT04    600000\n",
      "ACT03    600000\n",
      "ACT01    600000\n",
      "ACT13    561829\n",
      "ACT34     67410\n",
      "ACT35     23273\n",
      "ACT29     20429\n",
      "ACT16      2002\n",
      "Name: count, dtype: int64\n",
      "(6074943, 7)\n"
     ]
    }
   ],
   "source": [
    "print(train['Activity'].value_counts())\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity\n",
      "ACT17    600000\n",
      "ACT44    600000\n",
      "ACT32    600000\n",
      "ACT09    600000\n",
      "ACT15    600000\n",
      "ACT07    600000\n",
      "ACT04    600000\n",
      "ACT03    600000\n",
      "ACT01    600000\n",
      "ACT13    561829\n",
      "Name: count, dtype: int64\n",
      "(5961829, 7)\n"
     ]
    }
   ],
   "source": [
    "# Drop rows of train set with Activity = ACT34 or ACT35 or ACT29 or ACT16 \n",
    "train = train[train.Activity != 'ACT34']\n",
    "train = train[train.Activity != 'ACT35']\n",
    "train = train[train.Activity != 'ACT29']\n",
    "train = train[train.Activity != 'ACT16']\n",
    "\n",
    "print(train['Activity'].value_counts())\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    GjaeRecId  GroupChartOfAccountsValue  PostingLayer   \n",
      "0  5649334825                        170             0  \\\n",
      "1  5710479632                        203             0   \n",
      "2  5647433945                        194             0   \n",
      "3  5637301235                        276             0   \n",
      "4  5645359931                        168             2   \n",
      "\n",
      "   SubledgerVoucherDataAreaId  CreatedBy                             Text   \n",
      "0                          61        274  Amortissement depuis 31/05/2019  \\\n",
      "1                         106        216                 MALİ YIL AÇILIŞI   \n",
      "2                         105        237                MALİ YIL KAPANIŞI   \n",
      "3                          72        244  0100003317 -LYRECO ITALIA S.r.l   \n",
      "4                          67        147            Depr. since 31/3/2019   \n",
      "\n",
      "   Activity  \n",
      "0         7  \n",
      "1         9  \n",
      "2         9  \n",
      "3         8  \n",
      "4         7  \n"
     ]
    }
   ],
   "source": [
    "# Encode GroupChartOfAccountsValue column to numeric values \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "train['GroupChartOfAccountsValue'] = le.fit_transform(train['GroupChartOfAccountsValue'])\n",
    "test['GroupChartOfAccountsValue'] = le.fit_transform(test['GroupChartOfAccountsValue'])\n",
    "\n",
    "# Encode Activity column to numeric values\n",
    "le = LabelEncoder()\n",
    "train['Activity'] = le.fit_transform(train['Activity'])\n",
    "\n",
    "# Encode CreatedBy column to numeric values \n",
    "le = LabelEncoder()\n",
    "train['CreatedBy'] = le.fit_transform(train['CreatedBy'])\n",
    "test['CreatedBy'] = le.fit_transform(test['CreatedBy'])\n",
    "\n",
    "# Encode SubledgerVoucherDataAreaId column to numeric values\n",
    "le = LabelEncoder()\n",
    "train['SubledgerVoucherDataAreaId'] = le.fit_transform(train['SubledgerVoucherDataAreaId'])\n",
    "test['SubledgerVoucherDataAreaId'] = le.fit_transform(test['SubledgerVoucherDataAreaId'])\n",
    "\n",
    "# Print head of train set \n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity\n",
      "7    600000\n",
      "9    600000\n",
      "8    600000\n",
      "4    600000\n",
      "6    600000\n",
      "3    600000\n",
      "2    600000\n",
      "1    600000\n",
      "0    600000\n",
      "5    561829\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print values of Activity columm\n",
    "print(train['Activity'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    GjaeRecId  GroupChartOfAccountsValue  PostingLayer   \n",
      "0  5638693444                          1             0  \\\n",
      "1  5645683674                        178             0   \n",
      "2  5649471234                        194             0   \n",
      "3  5681568472                        235             0   \n",
      "4  5642402883                          1             0   \n",
      "\n",
      "   SubledgerVoucherDataAreaId  CreatedBy   \n",
      "0                          77        324  \\\n",
      "1                          42         56   \n",
      "2                          62        324   \n",
      "3                          63        179   \n",
      "4                          28         96   \n",
      "\n",
      "                                                Text  Activity  \n",
      "0                           allimentation compte mad         5  \n",
      "1                       31/12/2018 / KUR DEĞERLEMESİ         4  \n",
      "2                                          PI / 3487         1  \n",
      "3  Sales invoice - TPUK-INV000002069, Customer - ...         3  \n",
      "4                                         up 11.2018         5  \n",
      "    GjaeRecId  GroupChartOfAccountsValue  PostingLayer   \n",
      "0  5637145812                         56             0  \\\n",
      "1  5637145814                         56             0   \n",
      "2  5637145816                         56             0   \n",
      "3  5637145818                         56             0   \n",
      "4  5637145820                         56             0   \n",
      "\n",
      "   SubledgerVoucherDataAreaId  CreatedBy                    Text  \n",
      "0                          16          0  FXA MIGRATION 31/07/17  \n",
      "1                          16          0  FXA MIGRATION 31/07/17  \n",
      "2                          16          0  FXA MIGRATION 31/07/17  \n",
      "3                          16          0  FXA MIGRATION 31/07/17  \n",
      "4                          16          0  FXA MIGRATION 31/07/17  \n"
     ]
    }
   ],
   "source": [
    "# Data mixing\n",
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(train.head())\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove numbers from the rows in the 'Text' column of the train dataset\n",
    "train['Text'] = train['Text'].str.replace('\\d+', '')\n",
    "\n",
    "# Remove numbers from the rows in the 'Text' column of the test dataset\n",
    "test['Text'] = test['Text'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation and convert text to lowercase in the 'Text' column of 'train'\n",
    "train['Text'] = train['Text'].str.replace('[^\\w\\s]','').str.lower()\n",
    "\n",
    "# Remove punctuation and convert text to lowercase in the 'Text' column of 'test'\n",
    "test['Text'] = test['Text'].str.replace('[^\\w\\s]','').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                             allimentation compte mad\n",
      "1                        31/12/2018 / kur değerlemesi̇\n",
      "2                                            pi / 3487\n",
      "3    sales invoice - tpuk-inv000002069, customer - ...\n",
      "4                                           up 11.2018\n",
      "Name: Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print text of first 5 rows of train set\n",
    "print(train['Text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5961829, 6)\n",
      "(2444386, 5)\n"
     ]
    }
   ],
   "source": [
    "# Remove GjaeRecId column from test set and save it in a variable\n",
    "train = train.drop(['GjaeRecId'], axis=1)\n",
    "GjaeRecId = test['GjaeRecId']\n",
    "test = test.drop(['GjaeRecId'], axis=1)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# def remove_digits(text):\n",
    "#     if isinstance(text, str):\n",
    "#         return re.sub(r'\\b\\d+\\b', '', text)\n",
    "#     else:\n",
    "#         return text\n",
    "\n",
    "# # Applica la funzione sulla colonna 'Text' nel dataset di addestramento\n",
    "# train['Text'] = train['Text'].apply(remove_digits)\n",
    "\n",
    "# # Applica la funzione sulla colonna 'Text' nel dataset di test\n",
    "# test['Text'] = test['Text'].apply(remove_digits)\n",
    "\n",
    "\n",
    "# import string\n",
    "\n",
    "# # Rimuovi punteggiatura e converti il testo in minuscolo nella colonna 'Text' di 'train'\n",
    "# train['Text'] = train['Text'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)).lower() if isinstance(x, str) else x)\n",
    "\n",
    "# # Rimuovi punteggiatura e converti il testo in minuscolo nella colonna 'Text' di 'test'\n",
    "# test['Text'] = test['Text'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)).lower() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sostituisci i valori NaN con una stringa vuota nella colonna 'Text' di 'train'\n",
    "train['Text'] = train['Text'].fillna('')\n",
    "\n",
    "# Sostituisci i valori NaN con una stringa vuota nella colonna 'Text' di 'test'\n",
    "test['Text'] = test['Text'].fillna('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TF-IDF vectorizer to convert the text of the law into a matrix of TF-IDF features\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "# Fit and transform the TF-IDF vectorizer on the 'Text' column in 'train'\n",
    "tfidf_train = vectorizer.fit_transform(train['Text'])\n",
    "\n",
    "# Transform the 'Text' column in 'test'\n",
    "tfidf_test = vectorizer.transform(test['Text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8423957073583112\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93    120302\n",
      "           1       0.82      0.78      0.80    119658\n",
      "           2       0.99      0.90      0.94    119792\n",
      "           3       0.91      0.91      0.91    119860\n",
      "           4       0.73      0.80      0.76    119637\n",
      "           5       0.84      0.87      0.86    112574\n",
      "           6       0.87      0.39      0.54    120011\n",
      "           7       0.61      0.94      0.74    120745\n",
      "           8       0.93      0.87      0.90    120128\n",
      "           9       1.00      1.00      1.00    119659\n",
      "\n",
      "    accuracy                           0.84   1192366\n",
      "   macro avg       0.86      0.84      0.84   1192366\n",
      "weighted avg       0.86      0.84      0.84   1192366\n",
      "\n",
      "[[115415   2072]\n",
      " [  6921  93396]]\n"
     ]
    }
   ],
   "source": [
    "# Split the train dataset into train and validation sets \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(tfidf_train, train['Activity'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Import the Multinomial Naive Bayes classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Instantiate the MultinomialNB classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(X_val)\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "# Compute and print metrics\n",
    "print(\"Accuracy: {}\".format(metrics.accuracy_score(y_val, pred)))\n",
    "print(\"Classification Report:\\n {}\".format(metrics.classification_report(y_val, pred)))\n",
    "\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_val, pred, labels=[0, 1])\n",
    "print(cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instantiate the classifier\n",
    "rfc = RandomForestClassifier(random_state=42, n_jobs = 4)\n",
    "\n",
    "# Fit to the training data\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set: y_pred\n",
    "y_pred = rfc.predict(X_val)\n",
    "\n",
    "# Compute and print metrics\n",
    "print(\"Accuracy: {}\".format(metrics.accuracy_score(y_val, y_pred)))\n",
    "print(\"Classification Report:\\n {}\".format(metrics.classification_report(y_val, y_pred)))\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_val, y_pred, labels=[0, 1])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model selection for the logistic regression classifier using GridSearchCV \n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Setup the hyperparameter grid\n",
    "# # c_space = np.logspace(-5, 8, 15)\n",
    "# param_grid = {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2']}\n",
    "# logreg = LogisticRegression(random_state=42, max_iter=100, verbose=2)\n",
    "\n",
    "# # Instantiate the GridSearchCV object\n",
    "# logreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n",
    "\n",
    "# # Fit it to the training data\n",
    "# logreg_cv.fit(X_train, y_train)\n",
    "\n",
    "# # Print the optimal parameters and best score\n",
    "# print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n",
    "# print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
